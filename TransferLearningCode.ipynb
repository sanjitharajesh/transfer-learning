{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15c747",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your Desktop dataset folder\n",
    "base_path = Path.home() / \"Desktop\" / \"fdmproject\"\n",
    "\n",
    "# Adjust folder names as needed\n",
    "datasets = {\n",
    "    \"Pneumonia\": base_path / \"PneumoniaDataset\",\n",
    "    \"TB\": base_path / \"TB_split_dataset\"\n",
    "}\n",
    "\n",
    "def count_images(dataset_path):\n",
    "    counts = defaultdict(dict)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = dataset_path / split\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "        for cls in os.listdir(split_path):\n",
    "            cls_path = split_path / cls\n",
    "            if not cls_path.is_dir(): \n",
    "                continue\n",
    "            num_images = len([\n",
    "                f for f in os.listdir(cls_path)\n",
    "                if os.path.isfile(cls_path / f) and f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "            ])\n",
    "            counts[split][cls] = num_images\n",
    "    return counts\n",
    "\n",
    "# Report counts\n",
    "for name, path in datasets.items():\n",
    "    print(f\"\\nðŸ“Š {name} Dataset\")\n",
    "    stats = count_images(path)\n",
    "    for split, classes in stats.items():\n",
    "        print(f\"  {split.upper()}:\")\n",
    "        for cls, count in classes.items():\n",
    "            print(f\"    {cls:<10}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e60468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.expanduser(\"~/Desktop/fdmproject\")\n",
    "RAW_DATA = os.path.join(BASE_PATH, \"TBDataset\")  # Contains \"Normal\" and \"TB\"\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, \"TB_split_dataset\")\n",
    "\n",
    "tb_images = glob(os.path.join(RAW_DATA, \"TB\", \"*\"))\n",
    "normal_images = glob(os.path.join(RAW_DATA, \"Normal\", \"*\"))\n",
    "\n",
    "tb_train, tb_temp = train_test_split(tb_images, test_size=0.25, random_state=42)\n",
    "tb_val, tb_test = train_test_split(tb_temp, test_size=0.6, random_state=42)\n",
    "\n",
    "normal_train, normal_temp = train_test_split(normal_images, test_size=0.25, random_state=42)\n",
    "normal_val, normal_test = train_test_split(normal_temp, test_size=0.6, random_state=42)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for cls in [\"TB\", \"Normal\"]:\n",
    "        os.makedirs(os.path.join(OUTPUT_PATH, split, cls), exist_ok=True)\n",
    "        \n",
    "def copy_images(image_paths, dest_dir):\n",
    "    for path in image_paths:\n",
    "        shutil.copy(path, os.path.join(dest_dir, os.path.basename(path)))\n",
    "        \n",
    "copy_images(tb_train, os.path.join(OUTPUT_PATH, \"train\", \"TB\"))\n",
    "copy_images(tb_val, os.path.join(OUTPUT_PATH, \"val\", \"TB\"))\n",
    "copy_images(tb_test, os.path.join(OUTPUT_PATH, \"test\", \"TB\"))\n",
    "\n",
    "copy_images(normal_val, os.path.join(OUTPUT_PATH, \"val\", \"Normal\"))\n",
    "copy_images(normal_test, os.path.join(OUTPUT_PATH, \"test\", \"Normal\"))\n",
    "\n",
    "num_tb_train = len(tb_train)\n",
    "num_normal_train = len(normal_train)\n",
    "target_normal = num_tb_train\n",
    "images_to_generate = target_normal - num_normal_train\n",
    "\n",
    "augmentor = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.2)\n",
    "])\n",
    "\n",
    "normal_output_dir = os.path.join(OUTPUT_PATH, \"train\", \"Normal\")\n",
    "i = 0\n",
    "while i < images_to_generate:\n",
    "    img_path = random.choice(normal_train)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    augmented = augmentor(image=img)[\"image\"]\n",
    "    aug_img = Image.fromarray(augmented)\n",
    "    aug_img.save(os.path.join(normal_output_dir, f\"aug_normal_{i}.jpg\"))\n",
    "    i += 1\n",
    "    \n",
    "copy_images(normal_train, normal_output_dir)\n",
    "\n",
    "print(\"âœ… TB_split_dataset created with 75/10/15 split and balanced training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73fa21",
   "metadata": {},
   "source": [
    "**Data Augmentation and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2199e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61997db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_dir = Path.home() / \"Desktop\" / \"fdmproject\" / \"PneumoniaDataset\" / \"train\" / \"NORMAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688b8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect only augmented images (starting with 'aug_')\n",
    "augmented_images = sorted([\n",
    "    f for f in os.listdir(train_normal_dir)\n",
    "    if f.startswith('aug_') and f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "print(f\"Found {len(augmented_images)} augmented images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b464a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 600 to delete (randomly)\n",
    "num_to_delete = 600\n",
    "to_delete = random.sample(augmented_images, min(num_to_delete, len(augmented_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete them\n",
    "for fname in to_delete:\n",
    "    path = train_normal_dir / fname\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Deleted {len(to_delete)} augmented images from: {train_normal_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f74aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set base folder (adjust if needed)\n",
    "base_path = Path.home() / \"Desktop\" / \"fdmproject\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class folders\n",
    "classes = {\n",
    "    \"Pneumonia - NORMAL\": base_path / \"PneumoniaDataset\" / \"train\" / \"NORMAL\",\n",
    "    \"Pneumonia - PNEUMONIA\": base_path / \"PneumoniaDataset\" / \"train\" / \"PNEUMONIA\",\n",
    "    \"TB - Normal\": base_path / \"TB_split_dataset\" / \"train\" / \"Normal\",\n",
    "    \"TB - TB\": base_path / \"TB_split_dataset\" / \"train\" / \"TB\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples per class\n",
    "samples_per_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(classes), samples_per_class, figsize=(samples_per_class * 2, len(classes) * 2.5))\n",
    "fig.suptitle(\"ðŸ“Š Sample Images from Each Class\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, (label, path) in enumerate(classes.items()):\n",
    "    images = [f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    chosen = random.sample(images, min(samples_per_class, len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, fname in enumerate(chosen):\n",
    "        img_path = path / fname\n",
    "        img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "        axs[row, col].imshow(img, cmap='gray')\n",
    "        axs[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axs[row, col].set_title(label, loc='left', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56080cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image path (use any image from your dataset)\n",
    "img_path = Path.home() / \"Desktop\" / \"fdmproject\" / \"PneumoniaDataset\" / \"train\" / \"NORMAL\"\n",
    "sample_file = sorted(img_path.glob(\"*.jpeg\"))[0]  # Choose first .jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c396ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original\n",
    "original = Image.open(sample_file).convert('L')\n",
    "original_np = np.array(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "equalized = cv2.equalizeHist(original_np)\n",
    "resized = cv2.resize(equalized, (224, 224))\n",
    "normalized = (resized / 255.0 - 0.5) / 0.5  # Simulate torchvision.Normalize([0.5], [0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa422c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axs[0].imshow(original_np, cmap='gray')\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[1].imshow(equalized, cmap='gray')\n",
    "axs[1].set_title(\"Histogram Equalized\")\n",
    "axs[2].imshow(resized, cmap='gray')\n",
    "axs[2].set_title(\"Resized to 224x224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24728cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in axs: ax.axis('off')\n",
    "plt.suptitle(\"ðŸ§ª Image Preprocessing Steps\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1204e8c",
   "metadata": {},
   "source": [
    "**Model Training- Pneumonia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01651d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.expanduser(\"~/Desktop/fdmproject\")\n",
    "PNEUMONIA_PATH = os.path.join(BASE_PATH, \"PneumoniaDataset\")\n",
    "TB_PATH = os.path.join(BASE_PATH, \"TB_split_dataset\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 6\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def get_loaders(base):\n",
    "    return (\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'train'), transform), batch_size=BATCH_SIZE, shuffle=True),\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'val'), transform), batch_size=BATCH_SIZE),\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'test'), transform), batch_size=BATCH_SIZE),\n",
    "        datasets.ImageFolder(os.path.join(base, 'train'), transform).classes\n",
    "    )\n",
    "    \n",
    "p_train, p_val, p_test, p_classes = get_loaders(PNEUMONIA_PATH)\n",
    "t_train, t_val, t_test, t_classes = get_loaders(TB_PATH)\n",
    "\n",
    "def train_pneumonia():\n",
    "    model = models.efficientnet_b0(pretrained=True)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "        \n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    model.to(device)\n",
    "    \n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1560f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total, correct = 0, 0\n",
    "        for x, y in tqdm(p_train, desc=f\"[Pneumonia] Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            correct += (torch.argmax(out, 1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            \n",
    "torch.save(model.state_dict(), os.path.join(BASE_PATH, \"best_model_pneumonia.pth\"))\n",
    "    print(\"\\nâœ… Pneumonia model training complete. Best model saved.\")\n",
    "    \n",
    "print(\"\\nðŸ“Š Pneumonia Validation Evaluation:\")\n",
    "    evaluate(model, p_val, p_classes)\n",
    "    \n",
    "print(\"\\nðŸ“Š Pneumonia Test Evaluation:\")\n",
    "    evaluate(model, p_test, p_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38412d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)\n",
    "    \n",
    "@staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.lambda_, None\n",
    "\n",
    "def grad_reverse(x, lambda_):\n",
    "    return GradReverse.apply(x, lambda_)\n",
    "\n",
    "class DANN_EfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.efficientnet_b0(pretrained=False)\n",
    "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.classifier = nn.Linear(base.classifier[1].in_features, 2)\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(base.classifier[1].in_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "for name, param in self.feature_extractor.named_parameters():\n",
    "            if any(f\"features.{i}\" in name for i in [3, 4, 5, 6, 7]):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "def forward(self, x, lambda_=0.0):\n",
    "        features = self.feature_extractor(x).squeeze()\n",
    "        class_out = self.classifier(features)\n",
    "        domain_out = self.domain_classifier(grad_reverse(features, lambda_))\n",
    "        return class_out, domain_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c1a4e",
   "metadata": {},
   "source": [
    "**Model Training-TB with DANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f712111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dann():\n",
    "    model = DANN_EfficientNet().to(device)\n",
    "    pretrained = torch.load(os.path.join(BASE_PATH, \"best_model_pneumonia.pth\"), map_location=device)\n",
    "    model.load_state_dict({k: v for k, v in pretrained.items() if k in model.state_dict() and v.size() == model.state_dict()[k].size()}, strict=False)\n",
    "    \n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_class = nn.CrossEntropyLoss()\n",
    "    loss_domain = nn.CrossEntropyLoss()\n",
    "    \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        zipped = zip(t_train, p_train)\n",
    "        for (x_t, y_t), (x_s, _) in tqdm(zipped, desc=f\"[TB DANN] Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "            x_t, y_t = x_t.to(device), y_t.to(device)\n",
    "            x_s = x_s.to(device)\n",
    "            \n",
    "x_all = torch.cat([x_t, x_s], dim=0)\n",
    "            domain_labels = torch.cat([\n",
    "                torch.ones(x_t.size(0)),\n",
    "                torch.zeros(x_s.size(0))\n",
    "            ]).long().to(device)\n",
    "            \n",
    "            \n",
    "class_out, domain_out = model(x_all, lambda_=0.1)\n",
    "            loss = loss_class(class_out[:x_t.size(0)], y_t) + loss_domain(domain_out, domain_labels)\n",
    "            \n",
    "opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "print(f\"Epoch {epoch+1}: DANN Loss = {total_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(BASE_PATH, \"dann_tb.pth\"))\n",
    "    print(\"DANN fine-tuned TB model saved as dann_tb.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7a58a",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, classes, return_acc=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)[0] if isinstance(model(x), tuple) else model(x)\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            preds = (probs[:, 1] > 0.6).long()  # Threshold tuning: TB only if >60% confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "    print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380474b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_acc:\n",
    "        return 100 * (np.array(all_preds) == np.array(all_labels).astype(int)).sum() / len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(\"\\nðŸ“Œ Step 2: Fine-tuning on TB with DANN\")\n",
    "    model = train_dann()\n",
    "    \n",
    "    print(\"\\nðŸ“Š TB Validation Evaluation:\")\n",
    "    evaluate(model, t_val, t_classes)\n",
    "    \n",
    "    print(\"\\nðŸ“Š TB Test Evaluation:\")\n",
    "    evaluate(model, t_test, t_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0568df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7fa64d",
   "metadata": {},
   "source": [
    "**Model Training and Evaluation: TB Final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a502985",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.expanduser(\"~/Desktop/fdmproject\")\n",
    "TB_PATH = os.path.join(BASE_PATH, \"TB_split_dataset\")\n",
    "PNEUMO_MODEL_PATH = os.path.join(BASE_PATH, \"best_model_pneumonia.pth\")\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def get_loaders(base):\n",
    "    return (\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'train'), transform), batch_size=BATCH_SIZE, shuffle=True),\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'val'), transform), batch_size=BATCH_SIZE),\n",
    "        DataLoader(datasets.ImageFolder(os.path.join(base, 'test'), transform), batch_size=BATCH_SIZE),\n",
    "        datasets.ImageFolder(os.path.join(base, 'train'), transform).classes\n",
    "    )\n",
    "    \n",
    "t_train, t_val, t_test, t_classes = get_loaders(TB_PATH)\n",
    "\n",
    "class SimpleEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.efficientnet_b0(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(base.classifier[1].in_features, 2)\n",
    "        )\n",
    "\n",
    "for name, param in self.feature_extractor.named_parameters():\n",
    "            if any(f\"features.{i}\" in name for i in [4, 5, 6, 7]):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "def forward(self, x):\n",
    "        features = self.feature_extractor(x).squeeze()\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04fcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EVALUATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def evaluate(model, loader, classes, return_acc=False, silent=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            preds = (probs[:, 1] > 0.45).long()  # Lower threshold to improve Normal recall\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66674336",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not silent:\n",
    "        print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "        print(confusion_matrix(all_labels, all_preds))\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], '--')\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_acc:\n",
    "        return 100 * (np.array(all_preds) == np.array(all_labels)).sum() / len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e566f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TRAINING\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def train_transfer_model():\n",
    "    class EarlyStopper:\n",
    "        def __init__(self, patience=2):\n",
    "            self.patience = patience\n",
    "            self.counter = 0\n",
    "            self.best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde23104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(self, val_acc):\n",
    "            if val_acc > self.best_acc:\n",
    "                self.best_acc = val_acc\n",
    "                self.counter = 0\n",
    "                return False\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                return self.counter >= self.patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleEfficientNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pneumonia model weights\n",
    "    pretrained = torch.load(PNEUMO_MODEL_PATH, map_location=device)\n",
    "    model.load_state_dict({k: v for k, v in pretrained.items() if k in model.state_dict() and v.size() == model.state_dict()[k].size()}, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db547614",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1, weight=torch.tensor([1.1, 1.0]).to(device))\n",
    "    early_stopper = EarlyStopper(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bb1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in tqdm(t_train, desc=f\"[Transfer Learning] Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e304d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f} | Time: {elapsed:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b640b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = evaluate(model, t_val, t_classes, return_acc=True, silent=True)\n",
    "        print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "        if early_stopper.check(val_acc):\n",
    "            print(f\"ðŸ›‘ Early stopping triggered at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(BASE_PATH, \"transfer_tb_final.pth\"))\n",
    "    print(\"âœ… Final Transfer model saved as transfer_tb_final.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RUN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = train_transfer_model()\n",
    "print(\"\\nðŸ“Š Final TB Validation Evaluation:\")\n",
    "evaluate(model, t_val, t_classes, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80bce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Final TB Test Evaluation:\")\n",
    "evaluate(model, t_test, t_classes, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild model class\n",
    "class SimpleEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.efficientnet_b0(pretrained=False)\n",
    "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(base.classifier[1].in_features, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        features = self.feature_extractor(x).squeeze()\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e02f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SimpleEfficientNet()\n",
    "model.load_state_dict(torch.load(os.path.join(BASE_PATH, \"transfer_tb.pth\")))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all except classifier\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup fine-tune\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1.2, 1.0]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader for fine-tuning\n",
    "fine_tune_loader = DataLoader(\n",
    "    datasets.ImageFolder(os.path.join(TB_PATH, 'train'), transform),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 2 short epochs\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(fine_tune_loader, desc=f\"ðŸ›  Fine-tuning Epoch {epoch+1}/2\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93254b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned version\n",
    "torch.save(model.state_dict(), os.path.join(BASE_PATH, \"transfer_tb_normalboost.pth\"))\n",
    "print(\"âœ… Saved: transfer_tb_normalboost.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the same model structure\n",
    "class SimpleEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.efficientnet_b0(pretrained=False)\n",
    "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(base.classifier[1].in_features, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e200dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        features = self.feature_extractor(x).squeeze()\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate\n",
    "model = SimpleEfficientNet()\n",
    "model.load_state_dict(torch.load(os.path.join(BASE_PATH, \"transfer_tb_normalboost.pth\")))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1378bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Final Evaluation After Normal Recall Boost:\")\n",
    "evaluate(model, t_test, t_classes, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7231e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_PATH = os.path.expanduser(\"~/Desktop/fdmproject\")\n",
    "PNEUMO_PATH = os.path.join(BASE_PATH, \"PneumoniaDataset\", \"train\", \"NORMAL\")\n",
    "TB_PATH = os.path.join(BASE_PATH, \"TB_split_dataset\", \"train\", \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c09a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presentation-safe augmentations\n",
    "demo_augmentor = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),\n",
    "    A.GaussianBlur(blur_limit=3, p=1.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556507f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_augment(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    aug = demo_augmentor(image=image)[\"image\"]\n",
    "    return image, aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54648bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample images\n",
    "pneu_img_path = os.path.join(PNEUMO_PATH, random.choice(os.listdir(PNEUMO_PATH)))\n",
    "tb_img_path = os.path.join(TB_PATH, random.choice(os.listdir(TB_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e617a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneu_original, pneu_aug = load_and_augment(pneu_img_path)\n",
    "tb_original, tb_aug = load_and_augment(tb_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axs[0, 0].imshow(pneu_original); axs[0, 0].set_title(\"Pneumonia NORMAL - Original\")\n",
    "axs[0, 1].imshow(pneu_aug); axs[0, 1].set_title(\"Pneumonia NORMAL - Augmented\")\n",
    "axs[1, 0].imshow(tb_original); axs[1, 0].set_title(\"TB NORMAL - Original\")\n",
    "axs[1, 1].imshow(tb_aug); axs[1, 1].set_title(\"TB NORMAL - Augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7037c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in axs.flatten():\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ea0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
